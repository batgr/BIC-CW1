{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9595e8bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9595e8bd",
        "outputId": "aff2ec24-04be-407e-8c87-3507f75a06b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "%pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af9093fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af9093fd",
        "outputId": "b0edb834-168c-4161-f384-0867432ac3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 165, 'name': 'Concrete Compressive Strength', 'repository_url': 'https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength', 'data_url': 'https://archive.ics.uci.edu/static/public/165/data.csv', 'abstract': 'Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. ', 'area': 'Physics and Chemistry', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 1030, 'num_features': 8, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Concrete compressive strength'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1998, 'last_updated': 'Sun Feb 11 2024', 'dataset_doi': '10.24432/C5PK67', 'creators': ['I-Cheng Yeh'], 'intro_paper': {'ID': 383, 'type': 'NATIVE', 'title': 'Modeling of strength of high-performance concrete using artificial neural networks', 'authors': 'I. Yeh', 'venue': 'Cement and Concrete Research, Vol. 28, No. 12', 'year': 1998, 'journal': None, 'DOI': '10.1016/S0008-8846(98)00165-3', 'URL': 'https://www.semanticscholar.org/paper/9310cae70452ea11465f338483e79cc36a68881c', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Number of instances \\t1030\\r\\nNumber of Attributes\\t9\\r\\nAttribute breakdown\\t8 quantitative input variables, and 1 quantitative output variable\\r\\nMissing Attribute Values\\tNone \\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database. \\r\\n\\r\\nName -- Data Type -- Measurement -- Description\\r\\n\\r\\nCement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\\r\\nBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\\r\\nFly Ash (component 3) -- quantitative  -- kg in a m3 mixture -- Input Variable\\r\\nWater  (component 4) -- quantitative  -- kg in a m3 mixture -- Input Variable\\r\\nSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\\r\\nCoarse Aggregate  (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\\r\\nFine Aggregate (component 7)\\t -- quantitative  -- kg in a m3 mixture -- Input Variable\\r\\nAge -- quantitative  -- Day (1~365) -- Input Variable\\r\\nConcrete compressive strength -- quantitative -- MPa -- Output Variable\\r\\n\\r\\n', 'citation': None}}\n",
            "                            name     role        type demographic description  \\\n",
            "0                         Cement  Feature  Continuous        None        None   \n",
            "1             Blast Furnace Slag  Feature     Integer        None        None   \n",
            "2                        Fly Ash  Feature  Continuous        None        None   \n",
            "3                          Water  Feature  Continuous        None        None   \n",
            "4               Superplasticizer  Feature  Continuous        None        None   \n",
            "5               Coarse Aggregate  Feature  Continuous        None        None   \n",
            "6                 Fine Aggregate  Feature  Continuous        None        None   \n",
            "7                            Age  Feature     Integer        None        None   \n",
            "8  Concrete compressive strength   Target  Continuous        None        None   \n",
            "\n",
            "    units missing_values  \n",
            "0  kg/m^3             no  \n",
            "1  kg/m^3             no  \n",
            "2  kg/m^3             no  \n",
            "3  kg/m^3             no  \n",
            "4  kg/m^3             no  \n",
            "5  kg/m^3             no  \n",
            "6  kg/m^3             no  \n",
            "7     day             no  \n",
            "8     MPa             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "concrete_compressive_strength = fetch_ucirepo(id=165)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = concrete_compressive_strength.data.features\n",
        "y = concrete_compressive_strength.data.targets\n",
        "\n",
        "# metadata\n",
        "print(concrete_compressive_strength.metadata)\n",
        "\n",
        "# variable information\n",
        "print(concrete_compressive_strength.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4f5750",
      "metadata": {
        "id": "cb4f5750"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aff5880",
      "metadata": {
        "id": "3aff5880"
      },
      "outputs": [],
      "source": [
        "from ANN_PSO import ANN_PSO\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad50cba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ad50cba5",
        "outputId": "0ad4ac27-637e-48f0-b371-7303d4d3ceef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[57.92]\n",
            " [25.61]\n",
            " [33.49]\n",
            " [59.59]\n",
            " [29.55]\n",
            " [37.92]\n",
            " [61.86]\n",
            " [62.05]\n",
            " [32.01]\n",
            " [72.1 ]\n",
            " [39.  ]\n",
            " [65.7 ]\n",
            " [32.11]\n",
            " [40.29]\n",
            " [74.36]\n",
            " [21.97]\n",
            " [ 9.85]\n",
            " [15.07]\n",
            " [23.25]\n",
            " [43.73]\n",
            " [13.4 ]\n",
            " [24.13]\n",
            " [44.52]\n",
            " [62.94]\n",
            " [59.49]\n",
            " [25.12]\n",
            " [23.64]\n",
            " [35.75]\n",
            " [38.61]\n",
            " [68.75]\n",
            " [66.78]\n",
            " [23.85]\n",
            " [32.07]\n",
            " [11.65]\n",
            " [19.2 ]\n",
            " [48.85]\n",
            " [39.6 ]\n",
            " [43.94]\n",
            " [34.57]\n",
            " [54.32]\n",
            " [24.4 ]\n",
            " [15.62]\n",
            " [21.86]\n",
            " [10.22]\n",
            " [14.6 ]\n",
            " [18.75]\n",
            " [31.97]\n",
            " [23.4 ]\n",
            " [25.57]\n",
            " [41.68]\n",
            " [27.74]\n",
            " [ 8.2 ]\n",
            " [ 9.62]\n",
            " [25.42]\n",
            " [15.69]\n",
            " [27.94]\n",
            " [32.63]\n",
            " [17.24]\n",
            " [19.77]\n",
            " [39.44]\n",
            " [25.75]\n",
            " [33.08]\n",
            " [24.07]\n",
            " [21.82]\n",
            " [21.07]\n",
            " [14.84]\n",
            " [32.05]\n",
            " [11.96]\n",
            " [25.45]\n",
            " [22.49]\n",
            " [25.22]\n",
            " [39.7 ]\n",
            " [13.09]\n",
            " [38.7 ]\n",
            " [ 7.51]\n",
            " [17.58]\n",
            " [21.18]\n",
            " [18.2 ]\n",
            " [17.2 ]\n",
            " [22.63]\n",
            " [21.86]\n",
            " [12.37]\n",
            " [25.73]\n",
            " [37.81]\n",
            " [21.92]\n",
            " [33.04]\n",
            " [14.54]\n",
            " [26.91]\n",
            " [ 8.  ]\n",
            " [31.9 ]\n",
            " [10.34]\n",
            " [19.77]\n",
            " [37.44]\n",
            " [11.48]\n",
            " [24.44]\n",
            " [17.6 ]\n",
            " [10.73]\n",
            " [31.38]\n",
            " [13.22]\n",
            " [20.97]\n",
            " [27.04]\n",
            " [32.04]\n",
            " [35.17]\n",
            " [36.45]\n",
            " [38.89]\n",
            " [ 6.47]\n",
            " [12.84]\n",
            " [18.42]\n",
            " [21.95]\n",
            " [24.1 ]\n",
            " [25.08]\n",
            " [21.26]\n",
            " [25.97]\n",
            " [11.36]\n",
            " [31.25]\n",
            " [32.33]\n",
            " [33.7 ]\n",
            " [ 9.31]\n",
            " [26.94]\n",
            " [27.63]\n",
            " [29.79]\n",
            " [34.49]\n",
            " [36.15]\n",
            " [12.54]\n",
            " [27.53]\n",
            " [32.92]\n",
            " [ 9.99]\n",
            " [ 7.84]\n",
            " [12.25]\n",
            " [11.17]\n",
            " [17.34]\n",
            " [17.54]\n",
            " [30.57]\n",
            " [14.2 ]\n",
            " [24.5 ]\n",
            " [15.58]\n",
            " [26.85]\n",
            " [26.06]\n",
            " [38.21]\n",
            " [43.7 ]\n",
            " [30.14]\n",
            " [12.73]\n",
            " [20.87]\n",
            " [20.28]\n",
            " [34.29]\n",
            " [19.54]\n",
            " [47.71]\n",
            " [43.38]\n",
            " [29.89]\n",
            " [ 6.9 ]\n",
            " [33.19]\n",
            " [ 4.9 ]\n",
            " [ 4.57]\n",
            " [25.46]\n",
            " [24.29]\n",
            " [33.95]\n",
            " [11.41]\n",
            " [20.59]\n",
            " [25.89]\n",
            " [29.23]\n",
            " [31.02]\n",
            " [10.39]\n",
            " [33.66]\n",
            " [27.87]\n",
            " [19.35]\n",
            " [11.39]\n",
            " [12.79]\n",
            " [39.32]\n",
            " [ 4.78]\n",
            " [16.11]\n",
            " [43.38]\n",
            " [20.42]\n",
            " [ 6.94]\n",
            " [15.03]\n",
            " [13.57]\n",
            " [32.53]\n",
            " [15.75]\n",
            " [ 7.68]\n",
            " [38.8 ]\n",
            " [33.  ]\n",
            " [17.28]\n",
            " [24.28]\n",
            " [24.05]\n",
            " [36.59]\n",
            " [50.73]\n",
            " [13.66]\n",
            " [14.14]\n",
            " [47.78]\n",
            " [ 2.33]\n",
            " [16.89]\n",
            " [23.52]\n",
            " [ 6.81]\n",
            " [39.7 ]\n",
            " [17.96]\n",
            " [32.88]\n",
            " [22.35]\n",
            " [10.79]\n",
            " [ 7.72]\n",
            " [41.68]\n",
            " [ 9.56]\n",
            " [ 6.88]\n",
            " [50.53]\n",
            " [17.17]\n",
            " [30.44]\n",
            " [ 9.73]\n",
            " [ 3.32]\n",
            " [26.32]\n",
            " [43.25]\n",
            " [ 6.28]\n",
            " [32.1 ]\n",
            " [36.96]\n",
            " [54.6 ]\n",
            " [21.48]\n",
            " [ 9.69]\n",
            " [ 8.37]\n",
            " [39.66]\n",
            " [10.09]\n",
            " [ 4.83]\n",
            " [10.35]\n",
            " [43.57]\n",
            " [51.86]\n",
            " [11.85]\n",
            " [17.24]\n",
            " [27.83]\n",
            " [35.76]\n",
            " [38.7 ]\n",
            " [14.31]\n",
            " [17.44]\n",
            " [31.74]\n",
            " [37.91]\n",
            " [39.38]\n",
            " [15.87]\n",
            " [ 9.01]\n",
            " [33.61]\n",
            " [40.66]\n",
            " [40.86]\n",
            " [12.05]\n",
            " [17.54]\n",
            " [18.91]\n",
            " [25.18]\n",
            " [30.96]\n",
            " [43.89]\n",
            " [54.28]\n",
            " [36.94]\n",
            " [14.5 ]\n",
            " [22.44]\n",
            " [12.64]\n",
            " [26.06]\n",
            " [33.21]\n",
            " [36.94]\n",
            " [44.09]\n",
            " [52.61]\n",
            " [59.76]\n",
            " [67.31]\n",
            " [69.66]\n",
            " [71.62]\n",
            " [74.17]\n",
            " [18.13]\n",
            " [22.53]\n",
            " [27.34]\n",
            " [29.98]\n",
            " [31.35]\n",
            " [32.72]\n",
            " [ 6.27]\n",
            " [14.7 ]\n",
            " [23.22]\n",
            " [27.92]\n",
            " [31.35]\n",
            " [39.  ]\n",
            " [41.24]\n",
            " [14.99]\n",
            " [13.52]\n",
            " [24.  ]\n",
            " [37.42]\n",
            " [11.47]\n",
            " [22.44]\n",
            " [21.16]\n",
            " [31.84]\n",
            " [14.8 ]\n",
            " [25.18]\n",
            " [17.54]\n",
            " [14.2 ]\n",
            " [21.65]\n",
            " [29.39]\n",
            " [13.52]\n",
            " [16.26]\n",
            " [31.45]\n",
            " [37.23]\n",
            " [18.13]\n",
            " [32.72]\n",
            " [39.49]\n",
            " [41.05]\n",
            " [42.13]\n",
            " [18.13]\n",
            " [26.74]\n",
            " [61.92]\n",
            " [47.22]\n",
            " [51.04]\n",
            " [55.16]\n",
            " [41.64]\n",
            " [13.71]\n",
            " [19.69]\n",
            " [31.65]\n",
            " [19.11]\n",
            " [39.58]\n",
            " [48.79]\n",
            " [24.  ]\n",
            " [37.42]\n",
            " [11.47]\n",
            " [19.69]\n",
            " [14.99]\n",
            " [27.92]\n",
            " [34.68]\n",
            " [37.33]\n",
            " [38.11]\n",
            " [33.8 ]\n",
            " [42.42]\n",
            " [48.4 ]\n",
            " [55.94]\n",
            " [58.78]\n",
            " [67.11]\n",
            " [20.77]\n",
            " [25.18]\n",
            " [29.59]\n",
            " [21.75]\n",
            " [39.09]\n",
            " [24.39]\n",
            " [50.51]\n",
            " [74.99]\n",
            " [37.17]\n",
            " [33.76]\n",
            " [16.5 ]\n",
            " [19.99]\n",
            " [36.35]\n",
            " [33.69]\n",
            " [15.42]\n",
            " [33.42]\n",
            " [39.05]\n",
            " [27.68]\n",
            " [26.86]\n",
            " [45.3 ]\n",
            " [30.12]\n",
            " [15.57]\n",
            " [44.61]\n",
            " [53.52]\n",
            " [57.21]\n",
            " [65.91]\n",
            " [52.82]\n",
            " [33.4 ]\n",
            " [18.03]\n",
            " [37.36]\n",
            " [32.84]\n",
            " [42.64]\n",
            " [40.06]\n",
            " [41.94]\n",
            " [61.23]\n",
            " [40.87]\n",
            " [33.3 ]\n",
            " [52.42]\n",
            " [15.09]\n",
            " [38.46]\n",
            " [37.26]\n",
            " [35.23]\n",
            " [42.13]\n",
            " [31.87]\n",
            " [41.54]\n",
            " [39.45]\n",
            " [37.91]\n",
            " [44.28]\n",
            " [31.18]\n",
            " [23.69]\n",
            " [32.76]\n",
            " [32.4 ]\n",
            " [28.63]\n",
            " [36.8 ]\n",
            " [18.28]\n",
            " [33.06]\n",
            " [31.42]\n",
            " [31.03]\n",
            " [44.39]\n",
            " [12.18]\n",
            " [25.56]\n",
            " [36.44]\n",
            " [32.96]\n",
            " [23.84]\n",
            " [26.23]\n",
            " [17.95]\n",
            " [40.68]\n",
            " [19.01]\n",
            " [33.72]\n",
            " [ 8.54]\n",
            " [13.46]\n",
            " [32.24]\n",
            " [23.52]\n",
            " [29.72]\n",
            " [49.77]\n",
            " [52.44]\n",
            " [40.93]\n",
            " [44.86]\n",
            " [13.2 ]\n",
            " [37.43]\n",
            " [29.87]\n",
            " [56.61]\n",
            " [12.46]\n",
            " [23.79]\n",
            " [13.29]\n",
            " [39.42]\n",
            " [46.23]\n",
            " [44.52]\n",
            " [23.74]\n",
            " [26.14]\n",
            " [15.52]\n",
            " [43.57]\n",
            " [35.86]\n",
            " [41.05]\n",
            " [28.99]\n",
            " [46.24]\n",
            " [26.92]\n",
            " [10.54]\n",
            " [25.1 ]\n",
            " [29.07]\n",
            " [ 9.74]\n",
            " [33.8 ]\n",
            " [39.84]\n",
            " [26.97]\n",
            " [27.23]\n",
            " [30.65]\n",
            " [33.05]\n",
            " [24.58]\n",
            " [21.91]\n",
            " [30.88]\n",
            " [15.34]\n",
            " [24.34]\n",
            " [23.89]\n",
            " [22.93]\n",
            " [29.41]\n",
            " [28.63]\n",
            " [36.8 ]\n",
            " [18.29]\n",
            " [32.72]\n",
            " [31.42]\n",
            " [28.94]\n",
            " [40.93]\n",
            " [12.18]\n",
            " [25.56]\n",
            " [36.44]\n",
            " [32.96]\n",
            " [23.84]\n",
            " [26.23]\n",
            " [17.96]\n",
            " [38.63]\n",
            " [19.01]\n",
            " [33.72]\n",
            " [ 8.54]\n",
            " [13.46]\n",
            " [32.25]\n",
            " [23.52]\n",
            " [29.73]\n",
            " [49.77]\n",
            " [52.45]\n",
            " [40.93]\n",
            " [44.87]\n",
            " [13.2 ]\n",
            " [37.43]\n",
            " [29.87]\n",
            " [56.62]\n",
            " [12.46]\n",
            " [23.79]\n",
            " [13.29]\n",
            " [39.42]\n",
            " [46.23]\n",
            " [44.52]\n",
            " [23.74]\n",
            " [26.15]\n",
            " [15.53]\n",
            " [43.58]\n",
            " [35.87]\n",
            " [41.05]\n",
            " [28.99]\n",
            " [46.25]\n",
            " [26.92]\n",
            " [10.54]\n",
            " [25.1 ]\n",
            " [29.07]\n",
            " [ 9.74]\n",
            " [33.8 ]\n",
            " [37.17]\n",
            " [33.76]\n",
            " [16.5 ]\n",
            " [19.99]\n",
            " [36.35]\n",
            " [38.22]\n",
            " [15.42]\n",
            " [33.42]\n",
            " [39.06]\n",
            " [27.68]\n",
            " [26.86]\n",
            " [45.3 ]\n",
            " [30.12]\n",
            " [15.57]\n",
            " [44.61]\n",
            " [53.52]\n",
            " [57.22]\n",
            " [65.91]\n",
            " [52.83]\n",
            " [33.4 ]\n",
            " [18.03]\n",
            " [37.36]\n",
            " [35.31]\n",
            " [42.64]\n",
            " [40.06]\n",
            " [43.8 ]\n",
            " [61.24]\n",
            " [40.87]\n",
            " [33.31]\n",
            " [52.43]\n",
            " [15.09]\n",
            " [38.46]\n",
            " [37.27]\n",
            " [35.23]\n",
            " [42.14]\n",
            " [31.88]\n",
            " [41.54]\n",
            " [39.46]\n",
            " [37.92]\n",
            " [44.28]\n",
            " [31.18]\n",
            " [23.7 ]\n",
            " [32.77]\n",
            " [32.4 ]]\n"
          ]
        }
      ],
      "source": [
        "print(y.values[500:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5fb663c",
      "metadata": {
        "id": "c5fb663c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada19c2b",
      "metadata": {
        "id": "ada19c2b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. standardize the data\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "x_scaled = scaler_x.fit_transform(x.values)\n",
        "\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "x_train_scaled = x_scaled[:800]\n",
        "x_test_scaled  = x_scaled[800:]\n",
        "\n",
        "y_train_scaled = y_scaled[:800]\n",
        "y_test         = y.values[800:]\n",
        "\n",
        "# 2. initialize the model\n",
        "ann_pso = ANN_PSO(\n",
        "    [50,25,1],\n",
        "    \"tanh\", \"linear\",\n",
        "    60, 700,\n",
        "    0.8, 1.6, 0.95, 0.2, 0.0005,\n",
        "    -1.2, 1.2\n",
        ")\n",
        "\n",
        "# 3. train the model\n",
        "ann_pso.fit(x_train_scaled, y_train_scaled)\n",
        "\n",
        "# 4. predict and transform back to original scale\n",
        "y_pred_scaled = ann_pso.predict(x_test_scaled)\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "It took a long time to train, and in colab it need to train again if we close the page. So let's save the model\n"
      ],
      "metadata": {
        "id": "Af993g82d_eQ"
      },
      "id": "Af993g82d_eQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# save standardliser\n",
        "model_data = {\n",
        "    'ann_pso': ann_pso,\n",
        "    'scaler_X': scaler_X,\n",
        "    'scaler_y': scaler_y\n",
        "}\n",
        "\n",
        "with open('/content/concrete_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_data, f)\n",
        "\n",
        "print(\"Model saving success\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hTN8zGTdCKB",
        "outputId": "4a7bc727-9d3d-4361-dc45-1febf8f4833b"
      },
      "id": "9hTN8zGTdCKB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saving success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then let's load the model"
      ],
      "metadata": {
        "id": "n4jGIfHzfHay"
      },
      "id": "n4jGIfHzfHay"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    try:\n",
        "        with open('/content/concrete_model.pkl', 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        print(\"Data load successfully\")\n",
        "        return model_data['ann_pso'], model_data['scaler_X'], model_data['scaler_y']\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Fail to load: {e}\")\n",
        "        return None\n",
        "\n",
        "# load model\n",
        "ann_pso_loaded, scaler_X_loaded, scaler_y_loaded = load_model()\n",
        "\n",
        "if ann_pso_loaded is not None:\n",
        "    print(\"Model loaded successfully\")\n",
        "else:\n",
        "    print(\"Failed to load the model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07u-0My5ecix",
        "outputId": "5f5d3059-a3a2-4658-adde-7364f488e56f"
      },
      "id": "07u-0My5ecix",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data load successfully\n",
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca9be52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eca9be52",
        "outputId": "efb9083e-33fd-44ab-e0e9-693c660268be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [[10.03779966]\n",
            " [ 2.08302778]\n",
            " [21.65145428]\n",
            " [64.82472119]\n",
            " [62.62714602]\n",
            " [60.89249991]\n",
            " [45.92268457]\n",
            " [43.49303126]\n",
            " [11.1892558 ]\n",
            " [ 2.08302778]]\n",
            "true: [[13.71]\n",
            " [19.69]\n",
            " [31.65]\n",
            " [19.11]\n",
            " [39.58]\n",
            " [48.79]\n",
            " [24.  ]\n",
            " [37.42]\n",
            " [11.47]\n",
            " [19.69]]\n"
          ]
        }
      ],
      "source": [
        "print(\"pred:\", y_pred[:10])\n",
        "print(\"true:\", y_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2065d90",
      "metadata": {
        "id": "b2065d90",
        "outputId": "459b4400-a57d-4bcc-e5a2-abf2672dd1d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== FOLD 1/5 =====\n",
            "MAE  = 23.1960\n",
            "\n",
            "===== FOLD 2/5 =====\n",
            "MAE  = 22.2191\n",
            "\n",
            "===== FOLD 3/5 =====\n",
            "MAE  = 21.0435\n",
            "\n",
            "===== FOLD 4/5 =====\n",
            "MAE  = 20.4427\n",
            "\n",
            "===== FOLD 5/5 =====\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mae_scores, rmse_scores\n\u001b[32m     57\u001b[39m model_params = (\n\u001b[32m     58\u001b[39m     [\u001b[32m50\u001b[39m,\u001b[32m25\u001b[39m,\u001b[32m1\u001b[39m],         \u001b[38;5;66;03m# architecture\u001b[39;00m\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtanh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# activations\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     -\u001b[32m1.2\u001b[39m, \u001b[32m1.2\u001b[39m          \u001b[38;5;66;03m# min_bound, max_bound\u001b[39;00m\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m mae_scores, rmse_scores = \u001b[43mcross_validate_ann_pso\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcross_validate_ann_pso\u001b[39m\u001b[34m(X, y, model_params, n_splits)\u001b[39m\n\u001b[32m     31\u001b[39m ann = ANN_PSO(*model_params)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Entraîner\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mann\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Prédiction\u001b[39;00m\n\u001b[32m     37\u001b[39m y_pred_scaled = ann.predict(X_test_scaled)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/BIC-CW1/ANN_PSO.py:100\u001b[39m, in \u001b[36mANN_PSO.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.init_layers(dim_layers)\n\u001b[32m     99\u001b[39m dim = \u001b[38;5;28msum\u001b[39m((i+\u001b[32m1\u001b[39m)*j \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dim_layers[:-\u001b[32m1\u001b[39m],dim_layers[\u001b[32m1\u001b[39m:]))\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m params_opt = \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mswarmsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmin_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massess_fitness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mself\u001b[39m.init_params(params_opt)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/BIC-CW1/PSO.py:42\u001b[39m, in \u001b[36mpso\u001b[39m\u001b[34m(swarmsize, dim, n_iter, alpha, beta, gamma, sigma, epsilon, min_bound, max_bound, assess_fitness)\u001b[39m\n\u001b[32m     39\u001b[39m prev_best_fittest_informants = best_particles[best_idx]\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     b = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     c = np.random.uniform(\u001b[32m0.0\u001b[39m,gamma)\n\u001b[32m     44\u001b[39m     d = np.random.uniform(\u001b[32m0.0\u001b[39m,sigma)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def cross_validate_ann_pso(X, y, model_params, n_splits=5):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "\n",
        "    fold = 1\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "\n",
        "        print(f\"\\n===== FOLD {fold}/{n_splits} =====\")\n",
        "\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Standardisation\n",
        "        scaler_X = StandardScaler()\n",
        "        scaler_y = StandardScaler()\n",
        "\n",
        "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "        X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
        "        y_test_true = y_test  # valeurs réelles non-scalées\n",
        "\n",
        "        # Initialiser un nouveau modèle ANN_PSO\n",
        "        ann = ANN_PSO(*model_params)\n",
        "\n",
        "        # Entraîner\n",
        "        ann.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "        # Prédiction\n",
        "        y_pred_scaled = ann.predict(X_test_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "        # Metrics\n",
        "        mae  = mean_absolute_error(y_test_true, y_pred)\n",
        "\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "\n",
        "        print(f\"MAE  = {mae:.4f}\")\n",
        "\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    print(\"\\n========== Résultats finaux ==========\")\n",
        "    print(f\"MAE moyen  = {np.mean(mae_scores):.4f}  (± {np.std(mae_scores):.4f})\")\n",
        "    print(f\"RMSE moyen = {np.mean(rmse_scores):.4f}  (± {np.std(rmse_scores):.4f})\")\n",
        "\n",
        "    return mae_scores, rmse_scores\n",
        "model_params = (\n",
        "    [50,25,1],         # architecture\n",
        "    \"tanh\", \"linear\",  # activations\n",
        "    60, 700,           # swarmsize, n_iter\n",
        "    0.8, 1.6, 0.95,    # alpha, beta, gamma\n",
        "    0.2, 0.0005,       # sigma, epsilon\n",
        "    -1.2, 1.2          # min_bound, max_bound\n",
        ")\n",
        "mae_scores, rmse_scores = cross_validate_ann_pso(\n",
        "    X.values,\n",
        "    y.values,\n",
        "    model_params,\n",
        "    n_splits=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 : ANN Architecture Effects (with 5-Fold Cross Validation)\n",
        "\n"
      ],
      "metadata": {
        "id": "4qRqPi1copws"
      },
      "id": "4qRqPi1copws"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "\n",
        "def study_ann_architecture_with_cv():\n",
        "\n",
        "    print(\"STUDY 1: ANN Architecture Effects (with 5-Fold Cross Validation)\")\n",
        "\n",
        "    # Load data\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "    concrete_compressive_strength = fetch_ucirepo(id=165)\n",
        "    X = concrete_compressive_strength.data.features.values\n",
        "    y = concrete_compressive_strength.data.targets.values\n",
        "\n",
        "    # Create folder\n",
        "    study_dir = '/content/study1_architecture_cv'\n",
        "    os.makedirs(study_dir, exist_ok=True)\n",
        "\n",
        "    # Architectures set\n",
        "    architectures = [\n",
        "        ([10, 1], \"1hl_10n\"),\n",
        "        ([20, 10, 1], \"2hl_20_10n\"),\n",
        "        ([50, 25, 1], \"3hl_50_25n\"),\n",
        "        ([30, 20, 10, 1], \"4hl_30_20_10n\")\n",
        "    ]\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for arch, arch_name in architectures:\n",
        "        print(f\"\\n Testing architecture: {arch_name} - {arch}\")\n",
        "\n",
        "        # Parameters\n",
        "        model_params = (arch, \"tanh\", \"linear\", 30, 100, 0.8, 1.6, 0.95, 0.2, 0.0005, -1.2, 1.2)\n",
        "\n",
        "        # 10 times independent run & 5 fold cv\n",
        "        run_results = execute_independent_runs_with_cv(X, y, model_params, f\"arch_{arch_name}\",\n",
        "                                                      study_dir, n_runs=10, n_splits=5)\n",
        "        all_results.extend(run_results)\n",
        "\n",
        "    # save data\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "    results_file = f'{study_dir}/architecture_study_cv_results.csv'\n",
        "    results_df.to_csv(results_file, index=False)\n",
        "\n",
        "    print(f\"\\n Completed! \")\n",
        "    print(f\" Results saved to: {results_file}\")\n",
        "\n",
        "    display_architecture_cv_results(results_df)\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "pGwzqUmUnGnG"
      },
      "id": "pGwzqUmUnGnG",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 times independent run & 5 fold cv"
      ],
      "metadata": {
        "id": "qRsOx7dwrWyk"
      },
      "id": "qRsOx7dwrWyk"
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_independent_runs_with_cv(X, y, model_params, config_name, study_dir, n_runs=10, n_splits=5):\n",
        "# 10 times independent run & 5 fold cv\n",
        "    results = []\n",
        "\n",
        "    for run in range(n_runs):\n",
        "        run_name = f\"{config_name}_run{run+1:02d}\"\n",
        "        print(f\" {run_name} (with {n_splits}-fold CV)...\")\n",
        "\n",
        "        # If result exist?\n",
        "        result_file = f\"{study_dir}/cv_results_{run_name}.pkl\"\n",
        "\n",
        "        if os.path.exists(result_file):\n",
        "            # Load exist result\n",
        "            with open(result_file, 'rb') as f:\n",
        "                run_result = pickle.load(f)\n",
        "            print(f\"  Loaded existing CV results - Avg MAE: {run_result['cv_mae_mean']:.4f}\")\n",
        "        else:\n",
        "            # execute new one\n",
        "            run_result = execute_single_cv_run(X, y, model_params, run, run_name, n_splits)\n",
        "\n",
        "            # save result\n",
        "            with open(result_file, 'wb') as f:\n",
        "                pickle.dump(run_result, f)\n",
        "\n",
        "            print(f\"CV - Avg MAE: {run_result['cv_mae_mean']:.4f} ± {run_result['cv_mae_std']:.4f}\")\n",
        "\n",
        "        results.append(run_result)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "CryhigjSq_UF"
      },
      "id": "CryhigjSq_UF",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single run with 5 folds"
      ],
      "metadata": {
        "id": "1_uUUTzara19"
      },
      "id": "1_uUUTzara19"
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_single_cv_run(X, y, model_params, run_seed, run_name, n_splits=5):\n",
        "# Single run with 5 folds\n",
        "    start_time = time.time()\n",
        "\n",
        "    # random seeds\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42 + run_seed * 13)\n",
        "\n",
        "    fold_mae_scores = []\n",
        "    fold_rmse_scores = []\n",
        "    fold_times = []\n",
        "    all_fold_results = []\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "        fold_start = time.time()\n",
        "\n",
        "        # Data preparation\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Standardisation\n",
        "        scaler_X = StandardScaler()\n",
        "        scaler_y = StandardScaler()\n",
        "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "        X_test_scaled = scaler_X.transform(X_test)\n",
        "        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "\n",
        "        # Modle train\n",
        "        ann = ANN_PSO(*model_params)\n",
        "        ann.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "        # predictation\n",
        "        y_pred_scaled = ann.predict(X_test_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "        # Evaluation\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "        fold_time = time.time() - fold_start\n",
        "\n",
        "        # Save all result\n",
        "        fold_result = {\n",
        "            'fold': fold + 1,\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'training_time': fold_time,\n",
        "            'y_test': y_test,\n",
        "            'y_pred': y_pred\n",
        "        }\n",
        "        all_fold_results.append(fold_result)\n",
        "\n",
        "        fold_mae_scores.append(mae)\n",
        "        fold_rmse_scores.append(rmse)\n",
        "        fold_times.append(fold_time)\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    result = {\n",
        "        'run_name': run_name,\n",
        "        'config_name': run_name.split('_run')[0],\n",
        "        'cv_mae_mean': np.mean(fold_mae_scores),\n",
        "        'cv_mae_std': np.std(fold_mae_scores),\n",
        "        'cv_rmse_mean': np.mean(fold_rmse_scores),\n",
        "        'cv_rmse_std': np.std(fold_rmse_scores),\n",
        "        'cv_time_mean': np.mean(fold_times),\n",
        "        'cv_time_std': np.std(fold_times),\n",
        "        'total_training_time': total_time,\n",
        "        'model_params': model_params,\n",
        "        'run_seed': run_seed,\n",
        "        'n_splits': n_splits,\n",
        "        'fold_results': all_fold_results,\n",
        "        'timestamp': time.time()\n",
        "    }\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "3HvEquFFrDh4"
      },
      "id": "3HvEquFFrDh4",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results"
      ],
      "metadata": {
        "id": "KR5kLHVarc2o"
      },
      "id": "KR5kLHVarc2o"
    },
    {
      "cell_type": "code",
      "source": [
        "def display_architecture_cv_results(results_df):\n",
        "\n",
        "    print(\"\\n ARCHITECTURE STUDY - CROSS VALIDATION RESULTS\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    summary = results_df.groupby('config_name').agg({\n",
        "        'cv_mae_mean': ['mean', 'std', 'min', 'max'],\n",
        "        'cv_rmse_mean': ['mean', 'std'],\n",
        "        'cv_time_mean': ['mean', 'std'],\n",
        "        'total_training_time': 'mean'\n",
        "    }).round(4)\n",
        "\n",
        "    print(\"Cross-Validation Performance (Mean ± Std across 10 independent runs):\")\n",
        "    print(summary)\n",
        "\n",
        "    # Find Best run\n",
        "    best_run = results_df.loc[results_df['cv_mae_mean'].idxmin()]\n",
        "    print(f\"\\n BEST CONFIGURATION: {best_run['run_name']}\")\n",
        "    print(f\"   CV MAE: {best_run['cv_mae_mean']:.4f} ± {best_run['cv_mae_std']:.4f}\")\n",
        "    print(f\"   Architecture: {best_run['model_params'][0]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "o-ay3Y2YrHFI"
      },
      "id": "o-ay3Y2YrHFI",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "architecture_cv_results = study_ann_architecture_with_cv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8onmeY-q1kc",
        "outputId": "31c4c3c2-d3d1-4133-eb7b-417638581589"
      },
      "id": "d8onmeY-q1kc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STUDY 1: ANN Architecture Effects (with 5-Fold Cross Validation)\n",
            "\n",
            " Testing architecture: 1hl_10n - [10, 1]\n",
            " arch_1hl_10n_run01 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.2909\n",
            " arch_1hl_10n_run02 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 14.4590\n",
            " arch_1hl_10n_run03 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.9271\n",
            " arch_1hl_10n_run04 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.4454\n",
            " arch_1hl_10n_run05 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 16.9292\n",
            " arch_1hl_10n_run06 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.1520\n",
            " arch_1hl_10n_run07 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.6284\n",
            " arch_1hl_10n_run08 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 13.2228\n",
            " arch_1hl_10n_run09 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.3313\n",
            " arch_1hl_10n_run10 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 14.7720\n",
            "\n",
            " Testing architecture: 2hl_20_10n - [20, 10, 1]\n",
            " arch_2hl_20_10n_run01 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 16.3294\n",
            " arch_2hl_20_10n_run02 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 16.1919\n",
            " arch_2hl_20_10n_run03 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 14.2686\n",
            " arch_2hl_20_10n_run04 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 17.2992\n",
            " arch_2hl_20_10n_run05 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 14.5748\n",
            " arch_2hl_20_10n_run06 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.8647\n",
            " arch_2hl_20_10n_run07 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.7386\n",
            " arch_2hl_20_10n_run08 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.1693\n",
            " arch_2hl_20_10n_run09 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 14.2807\n",
            " arch_2hl_20_10n_run10 (with 5-fold CV)...\n",
            "  Loaded existing CV results - Avg MAE: 15.6319\n",
            "\n",
            " Testing architecture: 3hl_50_25n - [50, 25, 1]\n",
            " arch_3hl_50_25n_run01 (with 5-fold CV)...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}